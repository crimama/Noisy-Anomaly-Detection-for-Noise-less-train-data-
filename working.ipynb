{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "from models import create_model \n",
    "import yaml \n",
    "from omegaconf import OmegaConf\n",
    "from arguments import jupyter_parser\n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "\n",
    "import logging\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from collections import OrderedDict\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, \\\n",
    "                            balanced_accuracy_score, classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from query_strategies import create_query_strategy, create_labeled_index\n",
    "from models import ResNetSimCLR\n",
    "from utils import NoIndent, MyEncoder\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "default_setting = './configs/benchmark/default_setting.yaml'\n",
    "strategy_setting = './configs/benchmark/entropy_sampling.yaml'\n",
    "cfg = jupyter_parser(default_setting, strategy_setting)\n",
    "\n",
    "\n",
    "# # dataset \n",
    "from datasets import create_dataset\n",
    "trainset, testset = create_dataset(\n",
    "        dataset_name    = cfg.DATASET.dataset_name,\n",
    "        datadir         = cfg.DATASET.datadir,\n",
    "        img_size        = cfg.DATASET.img_size,\n",
    "        mean            = cfg.DATASET.mean,\n",
    "        std             = cfg.DATASET.std,\n",
    "        aug_info        = cfg.DATASET.aug_info,\n",
    "        anomaly_ratio   = cfg.DATASET.anomaly_ratio,\n",
    "        **cfg.DATASET.get('params',{})\n",
    "    )   \n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "# # model \n",
    "# from models.simclr import ResNetSimCLR\n",
    "model = __import__('models').__dict__[cfg.MODEL.method](\n",
    "    modelname = cfg.MODEL.modelname,\n",
    "    out_dim   = cfg.MODEL.out_dim\n",
    ").to('cuda')\n",
    "\n",
    "# # criterion \n",
    "# criterion = __import__('criterions').__dict__[cfg.CRITERION.name](\n",
    "#     batch_size = cfg.DATASET.batch_size,\n",
    "#     **cfg.CRITERION.get('params',{})\n",
    "#     )\n",
    "\n",
    "# from accelerate import Accelerator\n",
    "# accelerator = Accelerator() \n",
    "# exp_name           = 'temp'\n",
    "# modelname          = cfg.MODEL.modelname\n",
    "# pretrained         = cfg.MODEL.pretrained\n",
    "# strategy_name           = cfg.AL.strategy\n",
    "# n_start            = cfg.AL.n_start\n",
    "# n_end              = cfg.AL.n_end\n",
    "# n_query            = cfg.AL.n_query\n",
    "# n_subset           = cfg.AL.n_subset\n",
    "# init_method        = cfg.AL.init.method\n",
    "# init_method_params = cfg.AL.init.get('params', {})\n",
    "# trainset           = trainset\n",
    "# validset           = testset\n",
    "# testset            = testset\n",
    "# criterion_name     = cfg.CRITERION.name\n",
    "# criterion_params   = cfg.CRITERION.get('params',{})\n",
    "# img_size           = cfg.DATASET.img_size\n",
    "# num_classes        = cfg.DATASET.num_classes\n",
    "# batch_size         = cfg.DATASET.batch_size\n",
    "# test_batch_size    = cfg.DATASET.test_batch_size\n",
    "# num_workers        = cfg.DATASET.num_workers\n",
    "# opt_name           = cfg.OPTIMIZER.opt_name\n",
    "# lr                 = cfg.OPTIMIZER.lr\n",
    "# opt_params         = cfg.OPTIMIZER.get('params',{})\n",
    "# epochs             = cfg.TRAIN.epochs\n",
    "# log_interval       = cfg.TRAIN.log_interval\n",
    "# use_wandb          = cfg.TRAIN.wandb.use\n",
    "# savedir            = 'temp'\n",
    "# seed               = cfg.DEFAULT.seed\n",
    "# accelerator        = accelerator\n",
    "# ckp_metric         = 'temp'\n",
    "# cfg                = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels = next(iter(trainloader))\n",
    "t_outputs, s_outputs = model(img.to('cuda'))\n",
    "loss_map = np.zeros((len(trainloader.dataset), 64,64))\n",
    "\n",
    "score_map = 1.\n",
    "for t, s in zip(t_outputs, s_outputs):\n",
    "    t,s = F.normalize(t,dim=1),F.normalize(s,dim=1) # channel wise normalize \n",
    "    sm = torch.sum((t - s) ** 2, 1, keepdim=True) # channel wise average \n",
    "    sm = F.interpolate(sm, size=(64, 64), mode='bilinear', align_corners=False) # Intepolation : (1,w,h) -> (1,64,64)\n",
    "    score_map = score_map * sm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_map(t_outputs:list, s_outputs:list) -> torch.Tensor:\n",
    "    '''\n",
    "    sm.shape = (B,1,64,64)\n",
    "    '''\n",
    "    score_map = 1.\n",
    "    for t, s in zip(t_outputs, s_outputs):\n",
    "        t,s = F.normalize(t,dim=1),F.normalize(s,dim=1) # channel wise normalize \n",
    "        sm = torch.sum((t - s) ** 2, 1, keepdim=True) # channel wise average \n",
    "        sm = F.interpolate(sm, size=(64, 64), mode='bilinear', align_corners=False) # Intepolation : (1,w,h) -> (1,64,64)\n",
    "        score_map = score_map * sm \n",
    "    return score_map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8385"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(130).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.3578, 5.2091, 5.2566, 4.8769, 5.0312, 5.6437, 5.2243, 5.1100, 5.6954,\n",
       "        5.9759, 5.4641, 4.8042, 4.2613, 4.5210, 5.2040, 5.2469, 4.6537, 4.8127,\n",
       "        5.5784, 5.6723, 4.7969, 4.9957, 4.0973, 5.4970, 4.7935, 5.0252, 4.4149,\n",
       "        4.5798, 4.9115, 5.6856, 5.7163, 4.5442], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_map.flatten(1).max(1)[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatDist(nn.Module):\n",
    "    def __init__(self, layers:list = [0,1,2,3]):\n",
    "        super(FeatDist,self).__init__()\n",
    "        self.layers = layers \n",
    "        \n",
    "    def forward(self, t_outputs, s_outputs):\n",
    "        t_outputs = [t_outputs[x] for x in self.layers]\n",
    "        s_outputs = [s_outputs[x] for x in self.layers]\n",
    "        \n",
    "        total_loss = 0 \n",
    "        for t,s in zip(t_outputs, s_outputs):\n",
    "            t,s = F.normalize(t, dim=1), F.normalize(s, dim=1)\n",
    "            total_loss += torch.sum((t.type(torch.float32) - s.type(torch.float32)) ** 2, 1).mean()\n",
    "        return total_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t,s in zip(t_outputs, s_outputs):\n",
    "    t,s = F.normalize(t, dim=1), F.normalize(s, dim=1)\n",
    "    break\n",
    "    # total_loss += torch.sum((t.type(torch.float32) - s.type(torch.float32)) ** 2, 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 28, 28])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 56, 56])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
