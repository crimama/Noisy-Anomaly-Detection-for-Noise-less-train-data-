{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: /Volume/Data/SVHN/train_32x32.mat\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: /Volume/Data/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "from models import create_model \n",
    "import yaml \n",
    "from omegaconf import OmegaConf\n",
    "from arguments import jupyter_parser\n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "\n",
    "import logging\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from collections import OrderedDict\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, \\\n",
    "                            balanced_accuracy_score, classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from query_strategies import create_query_strategy, create_labeled_index\n",
    "from models import ResNetSimCLR\n",
    "from utils import NoIndent, MyEncoder\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "default_setting = './configs/benchmark/default_setting.yaml'\n",
    "strategy_setting = './configs/benchmark/entropy_sampling.yaml'\n",
    "cfg = jupyter_parser(default_setting, strategy_setting)\n",
    "\n",
    "\n",
    "# dataset \n",
    "from datasets import create_dataset\n",
    "trainset, testset = create_dataset(\n",
    "        normal_dataset  = cfg.DATASET.ID,\n",
    "        anomaly_dataset = cfg.DATASET.OOD,\n",
    "        datadir         = cfg.DATASET.datadir,\n",
    "        img_size        = cfg.DATASET.img_size,\n",
    "        mean            = cfg.DATASET.mean,\n",
    "        std             = cfg.DATASET.std,\n",
    "        aug_info        = cfg.DATASET.aug_info,\n",
    "        anomaly_ratio   = cfg.DATASET.anomaly_ratio,\n",
    "        total_size      = cfg.DATASET.total_size\n",
    "    )   \n",
    "from torch.utils.data import DataLoader \n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "# model \n",
    "from models.simclr import ResNetSimCLR\n",
    "model = ResNetSimCLR(\n",
    "                    modelname  = cfg.MODEL.modelname,\n",
    "                    img_size   = cfg.DATASET.img_size,\n",
    "                    pretrained = cfg.MODEL.pretrained,\n",
    "                    out_dim    = cfg.MODEL.out_dim\n",
    "                    )\n",
    "\n",
    "# criterion \n",
    "criterion = __import__('criterions').__dict__[cfg.CRITERION.name](\n",
    "    batch_size = cfg.DATASET.batch_size,\n",
    "    **cfg.CRITERION.get('params',{})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator() \n",
    "exp_name           = 'temp',\n",
    "modelname          = cfg.MODEL.modelname\n",
    "pretrained         = cfg.MODEL.pretrained\n",
    "strategy           = cfg.AL.strategy\n",
    "n_start            = cfg.AL.n_start\n",
    "n_end              = cfg.AL.n_end\n",
    "n_query            = cfg.AL.n_query\n",
    "n_subset           = cfg.AL.n_subset\n",
    "init_method        = cfg.AL.init.method\n",
    "init_method_params = cfg.AL.init.get('params', {})\n",
    "trainset           = trainset\n",
    "validset           = testset\n",
    "testset            = testset\n",
    "criterion_name     = cfg.CRITERION.name\n",
    "criterion_params   = cfg.CRITERION.get('params',{})\n",
    "img_size           = cfg.DATASET.img_size\n",
    "num_classes        = cfg.DATASET.num_classes\n",
    "batch_size         = cfg.DATASET.batch_size\n",
    "test_batch_size    = cfg.DATASET.test_batch_size\n",
    "num_workers        = cfg.DATASET.num_workers\n",
    "opt_name           = cfg.OPTIMIZER.opt_name\n",
    "lr                 = cfg.OPTIMIZER.lr\n",
    "opt_params         = cfg.OPTIMIZER.get('params',{})\n",
    "epochs             = cfg.TRAIN.epochs\n",
    "log_interval       = cfg.TRAIN.log_interval\n",
    "use_wandb          = cfg.TRAIN.wandb.use\n",
    "savedir            = 'temp'\n",
    "seed               = cfg.DEFAULT.seed\n",
    "accelerator        = accelerator\n",
    "ckp_metric         = 'temp'\n",
    "cfg                = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.AL.init.get('params',{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_labeled_index() argument after ** must be a mapping, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# inital sampling labeling\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m labeled_idx \u001b[39m=\u001b[39m create_labeled_index(\n\u001b[1;32m      3\u001b[0m     method   \u001b[39m=\u001b[39m init_method,\n\u001b[1;32m      4\u001b[0m     trainset \u001b[39m=\u001b[39m trainset,\n\u001b[1;32m      5\u001b[0m     size     \u001b[39m=\u001b[39m n_start,\n\u001b[1;32m      6\u001b[0m     seed     \u001b[39m=\u001b[39m seed,\n\u001b[1;32m      7\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minit_method_params\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[39m# create model \u001b[39;00m\n\u001b[1;32m     11\u001b[0m model \u001b[39m=\u001b[39m ResNetSimCLR(\n\u001b[1;32m     12\u001b[0m                 modelname  \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mMODEL\u001b[39m.\u001b[39mmodelname,\n\u001b[1;32m     13\u001b[0m                 img_size   \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mDATASET\u001b[39m.\u001b[39mimg_size,\n\u001b[1;32m     14\u001b[0m                 pretrained \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mMODEL\u001b[39m.\u001b[39mpretrained,\n\u001b[1;32m     15\u001b[0m                 out_dim    \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mMODEL\u001b[39m.\u001b[39mout_dim\n\u001b[1;32m     16\u001b[0m                 )\n",
      "\u001b[0;31mTypeError\u001b[0m: create_labeled_index() argument after ** must be a mapping, not tuple"
     ]
    }
   ],
   "source": [
    "# inital sampling labeling\n",
    "labeled_idx = create_labeled_index(\n",
    "    method   = init_method,\n",
    "    trainset = trainset,\n",
    "    size     = n_start,\n",
    "    seed     = seed,\n",
    "    **init_method_params\n",
    ")\n",
    "\n",
    "# create model \n",
    "model = ResNetSimCLR(\n",
    "                modelname  = cfg.MODEL.modelname,\n",
    "                img_size   = cfg.DATASET.img_size,\n",
    "                pretrained = cfg.MODEL.pretrained,\n",
    "                out_dim    = cfg.MODEL.out_dim\n",
    "                )\n",
    "\n",
    "# create criterion \n",
    "criterion = __import__('criterions').__dict__[criterion_name](\n",
    "                batch_size = batch_size,\n",
    "                **criterion_params\n",
    "                )\n",
    "\n",
    "# select strategy    \n",
    "strategy = create_query_strategy(\n",
    "    strategy_name = strategy, \n",
    "    model         = model,\n",
    "    dataset       = trainset, \n",
    "    labeled_idx   = labeled_idx, \n",
    "    n_query       = n_query, \n",
    "    batch_size    = batch_size, \n",
    "    num_workers   = num_workers,\n",
    "    params        = cfg.AL.get('params', {})\n",
    ")\n",
    "\n",
    "# define train dataloader\n",
    "trainloader = DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = batch_size,\n",
    "    sampler     = SubsetRandomSampler(indices=np.where(labeled_idx==False)[0]),\n",
    "    num_workers = num_workers\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
